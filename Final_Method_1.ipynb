{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "134 20\n",
      "135 20\n",
      "128 20\n",
      "133 20\n",
      "110 20\n",
      "203 20\n",
      "280 20\n",
      "123 20\n",
      "164 20\n",
      "244 20\n",
      "136 20\n",
      "180 20\n",
      "221 20\n",
      "147 20\n",
      "(10, 20, 100, 100) (10, 2)\n",
      "(10, 100, 100, 20) (10, 2)\n",
      "Epoch 1/4\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 618.7490 - accuracy: 0.4850\n",
      "Epoch 2/4\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 85.7633 - accuracy: 0.7475\n",
      "Epoch 3/4\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 3.8433 - accuracy: 0.8800\n",
      "Epoch 4/4\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.2797 - accuracy: 0.9675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2b991d40188>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import math\n",
    "from glob import glob \n",
    "\n",
    "\n",
    "\n",
    "IMG_SIZE_PX = 100\n",
    "SLICE_COUNT = 20\n",
    "\n",
    "def chunks(l, n):\n",
    "    # Credit: Ned Batchelder\n",
    "    # Link: http://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "\n",
    "\n",
    "def mean(a):\n",
    "    return sum(a) / len(a)\n",
    "\n",
    "\n",
    "def process_data(patient,labels_df,img_px_size=100, hm_slices=20, visualize=False):\n",
    "    \n",
    "    label = labels_df.at[patient, 'cancer']\n",
    "    path = data_dir + '/' + patient\n",
    "    slices = [pydicom.read_file(path + '/' +s ) for s in os.listdir(path)]\n",
    "    slices.sort(key = lambda x: int(x.ImagePositionPatient[2]))\n",
    "\n",
    "    new_slices = []\n",
    "\n",
    "    slices = [cv2.resize(np.array(each_slice.pixel_array),(img_px_size,img_px_size)) for each_slice in slices]\n",
    "    \n",
    "    chunk_sizes = math.ceil(len(slices) / hm_slices)\n",
    "    for slice_chunk in chunks(slices, chunk_sizes):\n",
    "        slice_chunk = list(map(mean, zip(*slice_chunk)))\n",
    "        new_slices.append(slice_chunk)\n",
    "        \n",
    "        \n",
    "    no = 20-len(new_slices)\n",
    "    \n",
    "    \n",
    "    if no > 0:\n",
    "        for s in range(no):    \n",
    "            new_slices.append(new_slices[-1])    \n",
    "        \n",
    "    if no < 0:\n",
    "        for j in range(abs(no)):\n",
    "            new_val = list(map(mean, zip(*[new_slices[hm_slices-1],new_slices[hm_slices],])))\n",
    "            del new_slices[hm_slices]\n",
    "            new_slices[hm_slices-1] = new_val \n",
    "    \n",
    "    print(len(slices), len(new_slices))        \n",
    "            \n",
    "    if label == 1: label=np.array([0,1])\n",
    "    elif label == 0: label=np.array([1,0])\n",
    "    \n",
    "    return np.array(new_slices),label\n",
    "    \n",
    "    \n",
    "'''    if len(new_slices) == hm_slices-1:\n",
    "        new_slices.append(new_slices[-1])\n",
    "\n",
    "    if len(new_slices) == hm_slices-2:\n",
    "        new_slices.append(new_slices[-1])\n",
    "        new_slices.append(new_slices[-1])\n",
    "\n",
    "    if len(new_slices) == hm_slices+2:\n",
    "        new_val = list(map(mean, zip(*[new_slices[hm_slices-1],new_slices[hm_slices]])))\n",
    "        del new_slices[hm_slices]\n",
    "        new_slices[hm_slices-1] = new_val\n",
    "        \n",
    "    if len(new_slices) == hm_slices+1:\n",
    "        new_val = list(map(mean, zip(*[new_slices[hm_slices-1],new_slices[hm_slices]])))\n",
    "        del new_slices[hm_slices]\n",
    "        new_slices[hm_slices-1] = new_val\n",
    "\n",
    "    if visualize:\n",
    "        fig = plt.figure()\n",
    "        for num,each_slice in enumerate(new_slices):\n",
    "            y = fig.add_subplot(4,5,num+1)\n",
    "            y.imshow(each_slice, cmap='gray')\n",
    "        plt.show()\n",
    "'''\n",
    "        \n",
    "        \n",
    "   \n",
    "\n",
    "# stage 1 for real.\n",
    "\n",
    "data_dir = 'N:/PROJECT/stage1'\n",
    "patients = os.listdir(data_dir)\n",
    "labels = pd.read_csv('N:/PROJECT/labels.csv', index_col=0)\n",
    "\n",
    "much_data = []\n",
    "for num,patient in enumerate(patients):\n",
    "    if num%100 == 0:\n",
    "        print(num)\n",
    "    try:\n",
    "        img_data,label = process_data(patient,labels,img_px_size=IMG_SIZE_PX, hm_slices=SLICE_COUNT)\n",
    "        #print(img_data.shape,label)\n",
    "        much_data.append([img_data,label])\n",
    "    except KeyError as e:\n",
    "        print('This is unlabeled data!')\n",
    "\n",
    "#np.save('muchdata-{}-{}-{}.npy'.format(IMG_SIZE_PX,IMG_SIZE_PX,SLICE_COUNT), much_data)\n",
    "\n",
    "\n",
    "for i in patients:\n",
    "    path = data_dir + '/' + i\n",
    "    slices = [pydicom.read_file(path + '/' +s ) for s in os.listdir(path)]\n",
    "    \n",
    "\n",
    "\n",
    "tr_img_data=[]\n",
    "label_train=[]\n",
    "s=np.array(much_data)\n",
    "\n",
    "for i in range(0,10):\n",
    "        z = np.array(s[i][0])\n",
    "        tr_img_data.append(np.array(z))\n",
    "        #label_train.append(s[i][1])\n",
    "        \n",
    "for i in range(0,10):\n",
    "        m = np.array(s[i][1])\n",
    "        label_train.append(np.array(m))\n",
    "        \n",
    "print(np.array(tr_img_data).shape,np.array(label_train).shape)    \n",
    "\n",
    "    \n",
    "d=np.array(tr_img_data)\n",
    "X = tf.reshape(d, shape=[-1,IMG_SIZE_PX, IMG_SIZE_PX, SLICE_COUNT])\n",
    "Y=np.array(label_train)\n",
    "print(X.shape,Y.shape) \n",
    "\n",
    "# Initialising the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(keras.layers.InputLayer(input_shape=(100,100,1)))\n",
    "\n",
    "# Step 1 - Convolution\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu',padding='valid'))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "#classifier.add(Dropout(0.5))\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Conv2D(64, (3, 3), activation = 'relu',padding='valid'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "#Adding dropout\n",
    "#classifier.add(Dropout(0.8))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 2, activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "list_data = []\n",
    "for i in range(0,10):\n",
    "    for j in range(0,20):\n",
    "        list_data.append([tr_img_data[i][j], label_train[i]])\n",
    "list_data = np.array(list_data)\n",
    "\n",
    "m = []\n",
    "n = []\n",
    "for i in range(0,200):\n",
    "    m.append(list_data[i][0])\n",
    "    n.append(list_data[i][1])\n",
    "m = np.array(m)\n",
    "n = np.array(n)\n",
    "\n",
    "m = np.reshape(m,[200,100,100,1])\n",
    "\n",
    "m.shape\n",
    "\n",
    "classifier.fit(m,n,epochs = 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The First test file patient has the cancerous cells.\n",
      "The patient has cancerous cells.\n",
      "The Second test file patient does not have cancerous cells.\n",
      "The patient does not have cancerous cells.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ds = pydicom.dcmread(\"N:/PROJECT/3b225245db9453efd9ad8a76b1598242.dcm\")\n",
    "ds1 = pydicom.dcmread(\"N:/PROJECT/7d71caeb22392e84f1d9d5b96429a5c7.dcm\")\n",
    "\n",
    "test_data = ds.pixel_array\n",
    "test_data1 = ds1.pixel_array\n",
    "\n",
    "test_data = cv2.resize(test_data, (100,100))\n",
    "test_data1 = cv2.resize(test_data1, (100,100))\n",
    "\n",
    "\n",
    "test_data = np.reshape(test_data, [1,100,100,1])\n",
    "test_data1 = np.reshape(test_data1, [1,100,100,1])\n",
    "\n",
    "pred = classifier.predict(test_data)\n",
    "pred1 = classifier.predict(test_data1)\n",
    "\n",
    "\n",
    "print(\"The First test file patient has the cancerous cells.\")\n",
    "\n",
    "if pred[0][1] > 0.5 :\n",
    "    print(\"The patient has cancerous cells.\")\n",
    "else:\n",
    "    print(\"The patient does not have cancerous cells.\")\n",
    "\n",
    "print(\"The Second test file patient does not have cancerous cells.\")\n",
    "\n",
    "if pred1[0][1]  < 0.5 :\n",
    "    print(\"The patient does not have cancerous cells.\")\n",
    "else:     \n",
    "    print(\"The patient has cancerous cells.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
